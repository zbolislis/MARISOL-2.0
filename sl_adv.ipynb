{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cde2b41",
   "metadata": {},
   "source": [
    "## **Importing Resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c51f39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers accelerate datasets scikit-learn torch pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae195f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aba672",
   "metadata": {},
   "source": [
    "## **Loading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021be7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_file = 'datasets/final/mpfc_train.csv'\n",
    "en_test_file = 'datasets/final/mpfc_test.csv'\n",
    "fil_train_file = 'datasets/final/fil_train.csv'\n",
    "fil_test_file = 'datasets/final/fil_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cfc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_df = pd.read_csv(en_train_file)\n",
    "en_test_df = pd.read_csv(en_test_file)\n",
    "fil_train_df = pd.read_csv(fil_train_file)\n",
    "fil_test_df = pd.read_csv(fil_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_df['label'] = en_train_df['label'].astype(int)\n",
    "fil_test_df['label'] = fil_test_df['label'].astype(int)\n",
    "en_test_df['label'] = en_test_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "117cf4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>code_frames</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senator Sherwin Gatchalian filed a civil lawsu...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVOID COLLATERAL DAMAGE FROM NRA'S CAMPAIGN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANILA – Human immunodeficiency virus (HIV) in...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANILA, Philippines – President Ferdinand Marc...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese Embassy in PH thanks DOJ over deporta...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>MANILA – President Ferdinand R. Marcos Jr. on ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Do you have a question on the news - local, na...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Davao Oriental 2nd district Rep. Cheeno Almari...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>The Philippine government is eyeing to deport ...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>devastating scores of families and the town th...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  code_frames  label\n",
       "0      Senator Sherwin Gatchalian filed a civil lawsu...            7      6\n",
       "1            AVOID COLLATERAL DAMAGE FROM NRA'S CAMPAIGN           15     14\n",
       "2      MANILA – Human immunodeficiency virus (HIV) in...            9      8\n",
       "3      MANILA, Philippines – President Ferdinand Marc...            2      1\n",
       "4      Japanese Embassy in PH thanks DOJ over deporta...           14     13\n",
       "...                                                  ...          ...    ...\n",
       "19995  MANILA – President Ferdinand R. Marcos Jr. on ...            2      1\n",
       "19996  Do you have a question on the news - local, na...           12     11\n",
       "19997  Davao Oriental 2nd district Rep. Cheeno Almari...           13     12\n",
       "19998  The Philippine government is eyeing to deport ...            7      6\n",
       "19999  devastating scores of families and the town th...           10      9\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b04027b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>code_frames</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physical distancing in classrooms may be eased...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bishop took on sensitive social issues\\r\\n</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANILA – President Ferdinand R. Marcos Jr. has...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Florida voters strongly support an increase in...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Supreme Court had approved new state death...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Telemachus 'Tel' Orfanos, 27, survived mass sh...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>\"Open Carry Picnic\" -- a mix of a typical outd...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>ASEAN first: Philippine presidents and their s...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>The Bureau of Immigration (BI) has stopped ano...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>MANILA, Philippines – The Philippines is still...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  code_frames  label\n",
       "0     Physical distancing in classrooms may be eased...           10      9\n",
       "1            Bishop took on sensitive social issues\\r\\n            3      2\n",
       "2     MANILA – President Ferdinand R. Marcos Jr. has...           14     13\n",
       "3     Florida voters strongly support an increase in...           12     11\n",
       "4     The Supreme Court had approved new state death...            5      4\n",
       "...                                                 ...          ...    ...\n",
       "4995  Telemachus 'Tel' Orfanos, 27, survived mass sh...           10      9\n",
       "4996  \"Open Carry Picnic\" -- a mix of a typical outd...           12     11\n",
       "4997  ASEAN first: Philippine presidents and their s...           13     12\n",
       "4998  The Bureau of Immigration (BI) has stopped ano...            7      6\n",
       "4999  MANILA, Philippines – The Philippines is still...           13     12\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8752029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa 110, missing 33 pa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masarap talagang chumibog ng malalamig na pagk...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Todas sa sama ng panahon 43 na — NDRRMC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mga gov’t worker may tig-20K bonus pa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 nirapido ng ‘Bonnet Gang’ sa kotse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>Kabataan Partylist, nakiisa sa kilos-protesta ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>DOH, nagbabala sa publiko vs karaniwang sakit ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Tuloy ang transport strike sa Marso 6 hanggang...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Barko sa Palawan, nasunog, lumubog; 2 tripulan...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>LPA, amihan, shear line, magpapaulan sa malaki...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                  Sa 110, missing 33 pa    NaN\n",
       "1      Masarap talagang chumibog ng malalamig na pagk...    NaN\n",
       "2                Todas sa sama ng panahon 43 na — NDRRMC    NaN\n",
       "3                  Mga gov’t worker may tig-20K bonus pa    NaN\n",
       "4                   3 nirapido ng ‘Bonnet Gang’ sa kotse    NaN\n",
       "...                                                  ...    ...\n",
       "19993  Kabataan Partylist, nakiisa sa kilos-protesta ...    NaN\n",
       "19994  DOH, nagbabala sa publiko vs karaniwang sakit ...    NaN\n",
       "19995  Tuloy ang transport strike sa Marso 6 hanggang...    NaN\n",
       "19996  Barko sa Palawan, nasunog, lumubog; 2 tripulan...    NaN\n",
       "19997  LPA, amihan, shear line, magpapaulan sa malaki...    NaN\n",
       "\n",
       "[19998 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c384f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>code_frames</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isang umano’y tinaguriang ‘shabu queen’ at lid...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthrax infection kumalat sa Cagayan</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TESDA: Mga tech-voc graduate swak sa trabaho</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nagkamit ng unang pwesto ang isang Filipina st...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEDA inaprub tapyas taripa sa e-vehicle</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Typhoon Betty, patuloy na humihina sa karagata...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>'Sarap maging tatay!' Post ng netizen tungkol ...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>TESDA, maglulunsad ng training programs para s...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>Anne Curtis, nagdiwang ng kaarawan sa ‘It’s Sh...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>Kamakailan lamang ay ibinida ng social media p...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  code_frames  label\n",
       "0     Isang umano’y tinaguriang ‘shabu queen’ at lid...            7      6\n",
       "1                  Anthrax infection kumalat sa Cagayan            9      8\n",
       "2          TESDA: Mga tech-voc graduate swak sa trabaho           10      9\n",
       "3     Nagkamit ng unang pwesto ang isang Filipina st...           15     14\n",
       "4               NEDA inaprub tapyas taripa sa e-vehicle            6      5\n",
       "...                                                 ...          ...    ...\n",
       "4979  Typhoon Betty, patuloy na humihina sa karagata...            9      8\n",
       "4980  'Sarap maging tatay!' Post ng netizen tungkol ...           11     10\n",
       "4981  TESDA, maglulunsad ng training programs para s...            2      1\n",
       "4982  Anne Curtis, nagdiwang ng kaarawan sa ‘It’s Sh...           15     14\n",
       "4983  Kamakailan lamang ay ibinida ng social media p...           15     14\n",
       "\n",
       "[4984 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda052f",
   "metadata": {},
   "source": [
    "## **Preparing Training Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b286d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model: 'bert-base-multilingual-cased' or 'xlm-roberta-base'\n",
    "model_name = 'xlm-roberta-base'\n",
    "\n",
    "# Training hyperparameters\n",
    "num_labels = 15\n",
    "max_length = 128\n",
    "learning_rate = 2e-5\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "num_epochs = 3\n",
    "weight_decay = 0.01\n",
    "\n",
    "# For self-training\n",
    "num_top_k = 40\n",
    "num_self_train = 3\n",
    "\n",
    "# For adversarial training\n",
    "adv_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d947a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c64e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds, average='weighted'),\n",
    "        'rmse': np.sqrt(mean_squared_error(labels, preds))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd2cf69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_name(model_name):\n",
    "    if 'roberta' in model_name:\n",
    "        return 'roberta.embeddings.word_embeddings'\n",
    "    elif 'bert' in model_name:\n",
    "        return 'bert.embeddings.word_embeddings'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model architecture in: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, adv_training=False, epsilon=1.0, emb_name=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.adv_training = adv_training\n",
    "        self.epsilon = epsilon\n",
    "        self.emb_name = emb_name\n",
    "        self.backup = {}\n",
    "\n",
    "        if self.adv_training and self.emb_name is None:\n",
    "            raise ValueError('Embedding layer name (`emb_name`) must be provided when adversarial training is enabled.')\n",
    "\n",
    "    def attack(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    param.data.add_(self.epsilon * param.grad / norm)\n",
    "\n",
    "    def restore(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                assert name in self.backup, f\"{name} not found in backup during restore\"\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "    def training_step(self, model, inputs, loss_fn=None):\n",
    "        loss = super().training_step(model, inputs, loss_fn)\n",
    "\n",
    "        if self.adv_training:\n",
    "            self.attack(model)\n",
    "            adv_loss = super().training_step(model, inputs, loss_fn)\n",
    "            self.restore(model)\n",
    "            loss += adv_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8260012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(train_dataset, unlabeled_dataset, logits, label_list, num_k):\n",
    "    probs = F.softmax(torch.tensor(logits), dim=-1)\n",
    "    confidences, pseudo_labels = torch.max(probs, dim=-1)\n",
    "\n",
    "    label2indices = {label: [] for label in label_list}\n",
    "    for idx, (pred, conf) in enumerate(zip(pseudo_labels, confidences)):\n",
    "        label2indices[pred.item()].append((idx, conf.item()))\n",
    "\n",
    "    selected_indices = []\n",
    "    print('Pseudo-labeled instance count per class:')\n",
    "    for label in label_list:\n",
    "        candidates = label2indices[label]\n",
    "        if not candidates:\n",
    "            print(f\"Class {label}: No confident instances\")\n",
    "            continue\n",
    "        sorted_indices = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "        top_k = sorted_indices[:num_k]\n",
    "        selected_indices.extend(idx for idx, _ in top_k)\n",
    "        top_confidences = [conf for _, conf in top_k]\n",
    "        min_conf = min(top_confidences)\n",
    "        max_conf = max(top_confidences)\n",
    "        print(f\"Class {label}: {len(top_k)} instances selected (out of {len(candidates)}), Confidence range: {min_conf:.4f}–{max_conf:.4f}\")\n",
    "\n",
    "    selected = [unlabeled_dataset[i].copy() for i in selected_indices]\n",
    "    for i, ex in zip(selected_indices, selected):\n",
    "        ex['label'] = int(pseudo_labels[i])\n",
    "\n",
    "    remaining_unlabeled = [unlabeled_dataset[i] for i in range(len(unlabeled_dataset)) if i not in selected_indices]\n",
    "    updated_train = train_dataset + selected\n",
    "    return updated_train, remaining_unlabeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f16519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trainer, train_dataset, unlabeled_dataset, label_list, num_k):\n",
    "    predictions = trainer.predict(unlabeled_dataset)\n",
    "    logits = predictions.predictions\n",
    "\n",
    "    updated_train, remaining_unlabeled = sort(train_dataset, unlabeled_dataset, logits, label_list, num_k)\n",
    "\n",
    "    return updated_train, remaining_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0196d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_training_loop():\n",
    "    \n",
    "    set_seed(42)\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(en_train_df).map(preprocess, batched=True).to_list()\n",
    "    unlabeled_dataset = Dataset.from_pandas(fil_train_df.drop(columns=['label'], errors='ignore')).map(preprocess, batched=True).to_list()\n",
    "    fil_val_dataset = Dataset.from_pandas(fil_test_df).map(preprocess, batched=True)\n",
    "    en_val_dataset = Dataset.from_pandas(en_test_df).map(preprocess, batched=True)\n",
    "\n",
    "    label_list = list(range(num_labels))\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    best_iteration = -1\n",
    "    best_epoch = -1\n",
    "\n",
    "    for i in range(num_self_train):\n",
    "        print(f\"\\nSELF-LEARNING ITERATION {i + 1}/{num_self_train}\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "        base_output_dir = f\"./results/sl_adv/{model_name.replace('/', '_')}\" if adv_training else f\"./results/sl/{model_name.replace('/', '_')}\"\n",
    "        iter_output_dir = f\"{base_output_dir}/iter_{i+1}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=iter_output_dir,\n",
    "            eval_strategy='epoch',            \n",
    "            save_strategy='epoch',\n",
    "            logging_strategy='epoch',\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            num_train_epochs=num_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='f1',\n",
    "            greater_is_better=True,\n",
    "            save_total_limit=1,\n",
    "            report_to='none',\n",
    "            seed=42,\n",
    "        )\n",
    "\n",
    "        # Prepare training dataset for this iteration\n",
    "        train_ds = Dataset.from_list(train_dataset).map(preprocess, batched=True)\n",
    "\n",
    "        # Detect embedding name only if adversarial training is on\n",
    "        embedding_name = get_embedding_name(model_name) if adv_training else None\n",
    "\n",
    "        # Create trainer\n",
    "        trainer = CustomTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=fil_val_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            adv_training=adv_training,\n",
    "            emb_name=embedding_name\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Run pseudo-labeling only if more training rounds are left\n",
    "        if i < num_self_train - 1:\n",
    "            train_dataset, unlabeled_dataset = predict(\n",
    "                trainer, train_dataset, unlabeled_dataset, label_list, num_top_k\n",
    "            )\n",
    "            print(f\"\\nTraining set size after this round: {len(train_dataset)}\")\n",
    "            print(f\"Remaining unlabeled examples after this round: {len(unlabeled_dataset)}\")\n",
    "\n",
    "        # Evaluate current model on Filipino validation set\n",
    "        fil_predictions = trainer.predict(fil_val_dataset)\n",
    "        fil_logits = fil_predictions.predictions\n",
    "        fil_labels = fil_predictions.label_ids if fil_predictions.label_ids is not None else np.argmax(fil_logits, axis=1)\n",
    "        fil_metrics = compute_metrics((fil_logits, fil_labels))\n",
    "        print(f\"Metrics on Filipino Validation Set: {fil_metrics}\")\n",
    "\n",
    "        # Evaluate current model on English validation set\n",
    "        en_predictions = trainer.predict(en_val_dataset)\n",
    "        en_logits = en_predictions.predictions\n",
    "        en_labels = en_predictions.label_ids if en_predictions.label_ids is not None else np.argmax(en_logits, axis=1)\n",
    "        en_metrics = compute_metrics((en_logits, en_labels))\n",
    "        print(f\"Metrics on English validation Set: {en_metrics}\")\n",
    "\n",
    "        if fil_metrics['f1'] > best_f1:\n",
    "            best_f1 = fil_metrics['f1']\n",
    "            best_iteration = i + 1\n",
    "            best_epoch = trainer.state.epoch\n",
    "            print(f\"New best model found on iteration {best_iteration}, epoch {best_epoch:.1f} with F1 = {best_f1:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest overall model was from iteration {best_iteration}, epoch {best_epoch:.1f} with F1 = {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63f99c",
   "metadata": {},
   "source": [
    "## **Self-learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc0cff",
   "metadata": {},
   "source": [
    "### mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe86de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 20095.54 examples/s]\n",
      "Map: 100%|██████████| 19998/19998 [00:00<00:00, 21045.70 examples/s]\n",
      "Map: 100%|██████████| 4984/4984 [00:00<00:00, 14318.86 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 24776.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELF-LEARNING ITERATION 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 24881.33 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 2:43:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.623100</td>\n",
       "      <td>1.836078</td>\n",
       "      <td>0.434791</td>\n",
       "      <td>0.444250</td>\n",
       "      <td>4.435375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.008200</td>\n",
       "      <td>1.965006</td>\n",
       "      <td>0.421148</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>4.353164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.759900</td>\n",
       "      <td>1.953064</td>\n",
       "      <td>0.441011</td>\n",
       "      <td>0.458741</td>\n",
       "      <td>4.232366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 791), Confidence range: 0.9181–0.9498\n",
      "Class 1: 40 instances selected (out of 1616), Confidence range: 0.8163–0.8618\n",
      "Class 2: 40 instances selected (out of 371), Confidence range: 0.9357–0.9631\n",
      "Class 3: 40 instances selected (out of 79), Confidence range: 0.5519–0.9036\n",
      "Class 4: 40 instances selected (out of 143), Confidence range: 0.7109–0.9436\n",
      "Class 5: 40 instances selected (out of 769), Confidence range: 0.9213–0.9352\n",
      "Class 6: 40 instances selected (out of 2557), Confidence range: 0.9771–0.9798\n",
      "Class 7: 40 instances selected (out of 584), Confidence range: 0.9017–0.9551\n",
      "Class 8: 40 instances selected (out of 2159), Confidence range: 0.9700–0.9721\n",
      "Class 9: 40 instances selected (out of 3066), Confidence range: 0.8990–0.9256\n",
      "Class 10: 40 instances selected (out of 374), Confidence range: 0.6817–0.8714\n",
      "Class 11: 40 instances selected (out of 223), Confidence range: 0.7922–0.9358\n",
      "Class 12: 40 instances selected (out of 2375), Confidence range: 0.9615–0.9661\n",
      "Class 13: 40 instances selected (out of 647), Confidence range: 0.9577–0.9673\n",
      "Class 14: 40 instances selected (out of 4244), Confidence range: 0.9159–0.9294\n",
      "\n",
      "Training set size after this round: 20600\n",
      "Remaining unlabeled examples after this round: 19398\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.4410112359550562, 'f1': 0.4587407732423319, 'rmse': np.float64(4.232365927978654)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.6906, 'f1': 0.689478321905268, 'rmse': np.float64(3.421841609426129)}\n",
      "New best model found on iteration 1, epoch 3.0 with F1 = 0.4587\n",
      "\n",
      "SELF-LEARNING ITERATION 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20600/20600 [00:01<00:00, 18227.43 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1932/1932 2:44:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.545200</td>\n",
       "      <td>2.062803</td>\n",
       "      <td>0.368579</td>\n",
       "      <td>0.390707</td>\n",
       "      <td>4.268924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>2.140092</td>\n",
       "      <td>0.393459</td>\n",
       "      <td>0.424088</td>\n",
       "      <td>4.195895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.734700</td>\n",
       "      <td>2.221549</td>\n",
       "      <td>0.388644</td>\n",
       "      <td>0.419401</td>\n",
       "      <td>4.130083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 1052), Confidence range: 0.9364–0.9512\n",
      "Class 1: 40 instances selected (out of 1414), Confidence range: 0.8041–0.8723\n",
      "Class 2: 40 instances selected (out of 294), Confidence range: 0.9271–0.9550\n",
      "Class 3: 40 instances selected (out of 234), Confidence range: 0.6925–0.9077\n",
      "Class 4: 40 instances selected (out of 628), Confidence range: 0.8531–0.9388\n",
      "Class 5: 40 instances selected (out of 1218), Confidence range: 0.8867–0.9269\n",
      "Class 6: 40 instances selected (out of 2029), Confidence range: 0.9681–0.9728\n",
      "Class 7: 40 instances selected (out of 647), Confidence range: 0.9143–0.9457\n",
      "Class 8: 40 instances selected (out of 2067), Confidence range: 0.9657–0.9686\n",
      "Class 9: 40 instances selected (out of 2677), Confidence range: 0.8742–0.9075\n",
      "Class 10: 40 instances selected (out of 1396), Confidence range: 0.8662–0.9031\n",
      "Class 11: 40 instances selected (out of 333), Confidence range: 0.8563–0.9255\n",
      "Class 12: 40 instances selected (out of 2049), Confidence range: 0.9511–0.9587\n",
      "Class 13: 40 instances selected (out of 699), Confidence range: 0.9481–0.9607\n",
      "Class 14: 40 instances selected (out of 2661), Confidence range: 0.9304–0.9400\n",
      "\n",
      "Training set size after this round: 21200\n",
      "Remaining unlabeled examples after this round: 18798\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.39345906902086675, 'f1': 0.42408771241429094, 'rmse': np.float64(4.1958953419629355)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.6866, 'f1': 0.6855292050832662, 'rmse': np.float64(3.4478108996869303)}\n",
      "\n",
      "SELF-LEARNING ITERATION 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 21200/21200 [00:01<00:00, 18308.04 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1989' max='1989' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1989/1989 2:54:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.534700</td>\n",
       "      <td>2.241271</td>\n",
       "      <td>0.342295</td>\n",
       "      <td>0.372288</td>\n",
       "      <td>4.415358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.933800</td>\n",
       "      <td>2.334151</td>\n",
       "      <td>0.356340</td>\n",
       "      <td>0.386868</td>\n",
       "      <td>4.197736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.359192</td>\n",
       "      <td>0.364767</td>\n",
       "      <td>0.398668</td>\n",
       "      <td>4.170065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.3647672552166934, 'f1': 0.3986676154162394, 'rmse': np.float64(4.170065494441229)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.696, 'f1': 0.694937290834445, 'rmse': np.float64(3.3450859480736814)}\n",
      "\n",
      "Best overall model was from iteration 1, epoch 3.0 with F1 = 0.4587\n"
     ]
    }
   ],
   "source": [
    "self_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d54d3",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5b8d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 26102.76 examples/s]\n",
      "Map: 100%|██████████| 19998/19998 [00:00<00:00, 24817.46 examples/s]\n",
      "Map: 100%|██████████| 4984/4984 [00:00<00:00, 28865.52 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 30312.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELF-LEARNING ITERATION 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 26001.68 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 3:09:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.671500</td>\n",
       "      <td>1.798217</td>\n",
       "      <td>0.442817</td>\n",
       "      <td>0.445454</td>\n",
       "      <td>4.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.037300</td>\n",
       "      <td>1.813685</td>\n",
       "      <td>0.461878</td>\n",
       "      <td>0.471468</td>\n",
       "      <td>3.837228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.828200</td>\n",
       "      <td>1.788131</td>\n",
       "      <td>0.472311</td>\n",
       "      <td>0.481530</td>\n",
       "      <td>3.831629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 1241), Confidence range: 0.9714–0.9769\n",
      "Class 1: 40 instances selected (out of 1044), Confidence range: 0.8541–0.8987\n",
      "Class 2: 40 instances selected (out of 342), Confidence range: 0.9642–0.9768\n",
      "Class 3: 40 instances selected (out of 109), Confidence range: 0.5864–0.9213\n",
      "Class 4: 40 instances selected (out of 156), Confidence range: 0.6945–0.9417\n",
      "Class 5: 40 instances selected (out of 1406), Confidence range: 0.9328–0.9515\n",
      "Class 6: 40 instances selected (out of 3998), Confidence range: 0.9737–0.9788\n",
      "Class 7: 40 instances selected (out of 402), Confidence range: 0.9127–0.9682\n",
      "Class 8: 40 instances selected (out of 2534), Confidence range: 0.9802–0.9820\n",
      "Class 9: 40 instances selected (out of 2799), Confidence range: 0.9049–0.9405\n",
      "Class 10: 40 instances selected (out of 990), Confidence range: 0.8950–0.9525\n",
      "Class 11: 40 instances selected (out of 407), Confidence range: 0.9395–0.9684\n",
      "Class 12: 40 instances selected (out of 2477), Confidence range: 0.9675–0.9730\n",
      "Class 13: 40 instances selected (out of 704), Confidence range: 0.9666–0.9763\n",
      "Class 14: 40 instances selected (out of 1389), Confidence range: 0.9302–0.9436\n",
      "\n",
      "Training set size after this round: 20600\n",
      "Remaining unlabeled examples after this round: 19398\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.47231139646869985, 'f1': 0.4815300293121325, 'rmse': np.float64(3.831628950894838)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.704, 'f1': 0.7018077952406384, 'rmse': np.float64(3.2116662342155045)}\n",
      "New best model found on iteration 1, epoch 3.0 with F1 = 0.4815\n",
      "\n",
      "SELF-LEARNING ITERATION 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20600/20600 [00:00<00:00, 31214.00 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1932/1932 3:02:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.627500</td>\n",
       "      <td>1.884882</td>\n",
       "      <td>0.410915</td>\n",
       "      <td>0.410790</td>\n",
       "      <td>3.933435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>1.835614</td>\n",
       "      <td>0.454655</td>\n",
       "      <td>0.472729</td>\n",
       "      <td>3.895376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.791800</td>\n",
       "      <td>1.861039</td>\n",
       "      <td>0.451846</td>\n",
       "      <td>0.465383</td>\n",
       "      <td>3.841644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 1013), Confidence range: 0.9654–0.9778\n",
      "Class 1: 40 instances selected (out of 1136), Confidence range: 0.8611–0.9114\n",
      "Class 2: 40 instances selected (out of 325), Confidence range: 0.9546–0.9721\n",
      "Class 3: 40 instances selected (out of 186), Confidence range: 0.6024–0.8615\n",
      "Class 4: 40 instances selected (out of 351), Confidence range: 0.7387–0.9404\n",
      "Class 5: 40 instances selected (out of 1265), Confidence range: 0.9014–0.9267\n",
      "Class 6: 40 instances selected (out of 3453), Confidence range: 0.9648–0.9745\n",
      "Class 7: 40 instances selected (out of 521), Confidence range: 0.8825–0.9606\n",
      "Class 8: 40 instances selected (out of 2024), Confidence range: 0.9783–0.9803\n",
      "Class 9: 40 instances selected (out of 2692), Confidence range: 0.8884–0.9184\n",
      "Class 10: 40 instances selected (out of 1300), Confidence range: 0.8318–0.8978\n",
      "Class 11: 40 instances selected (out of 420), Confidence range: 0.8935–0.9520\n",
      "Class 12: 40 instances selected (out of 1944), Confidence range: 0.9593–0.9712\n",
      "Class 13: 40 instances selected (out of 837), Confidence range: 0.9587–0.9702\n",
      "Class 14: 40 instances selected (out of 1931), Confidence range: 0.9074–0.9328\n",
      "\n",
      "Training set size after this round: 21200\n",
      "Remaining unlabeled examples after this round: 18798\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.4546548956661316, 'f1': 0.47272871500234676, 'rmse': np.float64(3.8953763183184513)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7024, 'f1': 0.7004673955561037, 'rmse': np.float64(3.2506922339710966)}\n",
      "\n",
      "SELF-LEARNING ITERATION 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 21200/21200 [00:00<00:00, 30812.17 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1989' max='1989' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1989/1989 3:09:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.615900</td>\n",
       "      <td>1.996241</td>\n",
       "      <td>0.415931</td>\n",
       "      <td>0.421244</td>\n",
       "      <td>3.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>1.875511</td>\n",
       "      <td>0.450642</td>\n",
       "      <td>0.467962</td>\n",
       "      <td>3.780998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.769300</td>\n",
       "      <td>1.958302</td>\n",
       "      <td>0.449037</td>\n",
       "      <td>0.466052</td>\n",
       "      <td>3.837803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.45064205457463885, 'f1': 0.46796242211360306, 'rmse': np.float64(3.7809981526704814)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.6986, 'f1': 0.6978094985033408, 'rmse': np.float64(3.2878260294608044)}\n",
      "\n",
      "Best overall model was from iteration 1, epoch 3.0 with F1 = 0.4815\n"
     ]
    }
   ],
   "source": [
    "self_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb10b3",
   "metadata": {},
   "source": [
    "## **Self-learning with Adversarial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe80d01",
   "metadata": {},
   "source": [
    "### mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fda7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 24236.53 examples/s]\n",
      "Map: 100%|██████████| 19998/19998 [00:00<00:00, 21063.76 examples/s]\n",
      "Map: 100%|██████████| 4984/4984 [00:00<00:00, 24431.12 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 15261.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELF-LEARNING ITERATION 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 24970.20 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 4:59:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.629200</td>\n",
       "      <td>1.714558</td>\n",
       "      <td>0.429976</td>\n",
       "      <td>0.436066</td>\n",
       "      <td>4.363821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.527800</td>\n",
       "      <td>1.786078</td>\n",
       "      <td>0.423957</td>\n",
       "      <td>0.441840</td>\n",
       "      <td>4.372572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.078900</td>\n",
       "      <td>1.715989</td>\n",
       "      <td>0.448836</td>\n",
       "      <td>0.464945</td>\n",
       "      <td>4.264128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 664), Confidence range: 0.8402–0.9122\n",
      "Class 1: 40 instances selected (out of 1102), Confidence range: 0.6725–0.7584\n",
      "Class 2: 40 instances selected (out of 333), Confidence range: 0.9013–0.9498\n",
      "Class 3: 40 instances selected (out of 75), Confidence range: 0.4044–0.8164\n",
      "Class 4: 40 instances selected (out of 54), Confidence range: 0.2863–0.8917\n",
      "Class 5: 40 instances selected (out of 675), Confidence range: 0.8523–0.9033\n",
      "Class 6: 40 instances selected (out of 3028), Confidence range: 0.9538–0.9648\n",
      "Class 7: 40 instances selected (out of 392), Confidence range: 0.7884–0.9154\n",
      "Class 8: 40 instances selected (out of 2321), Confidence range: 0.9580–0.9628\n",
      "Class 9: 40 instances selected (out of 3020), Confidence range: 0.8513–0.8869\n",
      "Class 10: 40 instances selected (out of 246), Confidence range: 0.4641–0.7304\n",
      "Class 11: 40 instances selected (out of 214), Confidence range: 0.6770–0.9053\n",
      "Class 12: 40 instances selected (out of 3121), Confidence range: 0.9347–0.9520\n",
      "Class 13: 40 instances selected (out of 577), Confidence range: 0.9218–0.9482\n",
      "Class 14: 40 instances selected (out of 4176), Confidence range: 0.9015–0.9158\n",
      "\n",
      "Training set size after this round: 20600\n",
      "Remaining unlabeled examples after this round: 19398\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.4488362760834671, 'f1': 0.4649451306977881, 'rmse': np.float64(4.264127684734299)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7052, 'f1': 0.703582213712078, 'rmse': np.float64(3.3456538972224847)}\n",
      "New best model found on iteration 1, epoch 3.0 with F1 = 0.4649\n",
      "\n",
      "SELF-LEARNING ITERATION 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20600/20600 [00:01<00:00, 17857.79 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1932/1932 5:16:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.533900</td>\n",
       "      <td>1.982036</td>\n",
       "      <td>0.366974</td>\n",
       "      <td>0.387634</td>\n",
       "      <td>4.302982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.466600</td>\n",
       "      <td>1.958667</td>\n",
       "      <td>0.392055</td>\n",
       "      <td>0.418403</td>\n",
       "      <td>4.236015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.027100</td>\n",
       "      <td>2.000459</td>\n",
       "      <td>0.394061</td>\n",
       "      <td>0.419446</td>\n",
       "      <td>4.207666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 916), Confidence range: 0.9128–0.9425\n",
      "Class 1: 40 instances selected (out of 1446), Confidence range: 0.7723–0.8311\n",
      "Class 2: 40 instances selected (out of 457), Confidence range: 0.9376–0.9543\n",
      "Class 3: 40 instances selected (out of 470), Confidence range: 0.7122–0.8885\n",
      "Class 4: 40 instances selected (out of 306), Confidence range: 0.7470–0.9261\n",
      "Class 5: 40 instances selected (out of 847), Confidence range: 0.8566–0.9136\n",
      "Class 6: 40 instances selected (out of 2332), Confidence range: 0.9505–0.9605\n",
      "Class 7: 40 instances selected (out of 738), Confidence range: 0.8780–0.9295\n",
      "Class 8: 40 instances selected (out of 2456), Confidence range: 0.9574–0.9624\n",
      "Class 9: 40 instances selected (out of 2683), Confidence range: 0.8891–0.9080\n",
      "Class 10: 40 instances selected (out of 1451), Confidence range: 0.8913–0.9183\n",
      "Class 11: 40 instances selected (out of 534), Confidence range: 0.8763–0.9308\n",
      "Class 12: 40 instances selected (out of 2168), Confidence range: 0.9430–0.9543\n",
      "Class 13: 40 instances selected (out of 615), Confidence range: 0.9256–0.9472\n",
      "Class 14: 40 instances selected (out of 1979), Confidence range: 0.9131–0.9276\n",
      "\n",
      "Training set size after this round: 21200\n",
      "Remaining unlabeled examples after this round: 18798\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.3940609951845907, 'f1': 0.4194462530252862, 'rmse': np.float64(4.207666129056767)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.698, 'f1': 0.6964769898433307, 'rmse': np.float64(3.4413078909042705)}\n",
      "\n",
      "SELF-LEARNING ITERATION 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 21200/21200 [00:01<00:00, 20502.40 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1989' max='1989' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1989/1989 5:18:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.479700</td>\n",
       "      <td>2.099655</td>\n",
       "      <td>0.359952</td>\n",
       "      <td>0.386892</td>\n",
       "      <td>4.273692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.366700</td>\n",
       "      <td>2.182828</td>\n",
       "      <td>0.366172</td>\n",
       "      <td>0.395093</td>\n",
       "      <td>4.186393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.946300</td>\n",
       "      <td>2.177252</td>\n",
       "      <td>0.376605</td>\n",
       "      <td>0.408916</td>\n",
       "      <td>4.190943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.3766051364365971, 'f1': 0.40891643099319636, 'rmse': np.float64(4.1909431892366795)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7102, 'f1': 0.7084034865391744, 'rmse': np.float64(3.3674916480965473)}\n",
      "\n",
      "Best overall model was from iteration 1, epoch 3.0 with F1 = 0.4649\n"
     ]
    }
   ],
   "source": [
    "self_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0cf7d",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "efdf313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 25740.09 examples/s]\n",
      "Map: 100%|██████████| 19998/19998 [00:00<00:00, 24342.71 examples/s]\n",
      "Map: 100%|██████████| 4984/4984 [00:00<00:00, 28604.56 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 31649.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELF-LEARNING ITERATION 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 26430.21 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 5:37:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.324400</td>\n",
       "      <td>1.719690</td>\n",
       "      <td>0.455257</td>\n",
       "      <td>0.462936</td>\n",
       "      <td>4.083130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.113400</td>\n",
       "      <td>1.715636</td>\n",
       "      <td>0.473315</td>\n",
       "      <td>0.484257</td>\n",
       "      <td>3.845402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.658800</td>\n",
       "      <td>1.725254</td>\n",
       "      <td>0.482544</td>\n",
       "      <td>0.491734</td>\n",
       "      <td>3.807122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 1089), Confidence range: 0.9747–0.9797\n",
      "Class 1: 40 instances selected (out of 930), Confidence range: 0.8710–0.9229\n",
      "Class 2: 40 instances selected (out of 351), Confidence range: 0.9610–0.9783\n",
      "Class 3: 40 instances selected (out of 112), Confidence range: 0.5806–0.9506\n",
      "Class 4: 40 instances selected (out of 143), Confidence range: 0.6308–0.9549\n",
      "Class 5: 40 instances selected (out of 1333), Confidence range: 0.9274–0.9561\n",
      "Class 6: 40 instances selected (out of 4106), Confidence range: 0.9784–0.9837\n",
      "Class 7: 40 instances selected (out of 454), Confidence range: 0.9232–0.9671\n",
      "Class 8: 40 instances selected (out of 2437), Confidence range: 0.9826–0.9853\n",
      "Class 9: 40 instances selected (out of 2703), Confidence range: 0.9067–0.9407\n",
      "Class 10: 40 instances selected (out of 944), Confidence range: 0.9012–0.9610\n",
      "Class 11: 40 instances selected (out of 400), Confidence range: 0.9348–0.9718\n",
      "Class 12: 40 instances selected (out of 2469), Confidence range: 0.9703–0.9779\n",
      "Class 13: 40 instances selected (out of 756), Confidence range: 0.9691–0.9784\n",
      "Class 14: 40 instances selected (out of 1771), Confidence range: 0.9397–0.9575\n",
      "\n",
      "Training set size after this round: 20600\n",
      "Remaining unlabeled examples after this round: 19398\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.4825441412520064, 'f1': 0.4917339887906747, 'rmse': np.float64(3.807122454087514)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7252, 'f1': 0.7240784101307837, 'rmse': np.float64(3.0986771371022184)}\n",
      "New best model found on iteration 1, epoch 3.0 with F1 = 0.4917\n",
      "\n",
      "SELF-LEARNING ITERATION 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20600/20600 [00:01<00:00, 20375.70 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1932/1932 5:35:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.271200</td>\n",
       "      <td>1.747432</td>\n",
       "      <td>0.445225</td>\n",
       "      <td>0.448992</td>\n",
       "      <td>3.865905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.052300</td>\n",
       "      <td>1.736007</td>\n",
       "      <td>0.470104</td>\n",
       "      <td>0.486185</td>\n",
       "      <td>3.861232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.628100</td>\n",
       "      <td>1.760985</td>\n",
       "      <td>0.471709</td>\n",
       "      <td>0.490147</td>\n",
       "      <td>3.846993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled instance count per class:\n",
      "Class 0: 40 instances selected (out of 1175), Confidence range: 0.9710–0.9775\n",
      "Class 1: 40 instances selected (out of 913), Confidence range: 0.8864–0.9248\n",
      "Class 2: 40 instances selected (out of 377), Confidence range: 0.9590–0.9767\n",
      "Class 3: 40 instances selected (out of 227), Confidence range: 0.6578–0.9371\n",
      "Class 4: 40 instances selected (out of 319), Confidence range: 0.7417–0.9271\n",
      "Class 5: 40 instances selected (out of 1296), Confidence range: 0.9233–0.9490\n",
      "Class 6: 40 instances selected (out of 3390), Confidence range: 0.9763–0.9820\n",
      "Class 7: 40 instances selected (out of 523), Confidence range: 0.8876–0.9628\n",
      "Class 8: 40 instances selected (out of 2361), Confidence range: 0.9842–0.9872\n",
      "Class 9: 40 instances selected (out of 2792), Confidence range: 0.8987–0.9301\n",
      "Class 10: 40 instances selected (out of 1263), Confidence range: 0.9110–0.9524\n",
      "Class 11: 40 instances selected (out of 497), Confidence range: 0.9291–0.9709\n",
      "Class 12: 40 instances selected (out of 2017), Confidence range: 0.9670–0.9766\n",
      "Class 13: 40 instances selected (out of 732), Confidence range: 0.9633–0.9742\n",
      "Class 14: 40 instances selected (out of 1516), Confidence range: 0.9442–0.9553\n",
      "\n",
      "Training set size after this round: 21200\n",
      "Remaining unlabeled examples after this round: 18798\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.4717094703049759, 'f1': 0.49014685382412704, 'rmse': np.float64(3.8469933643594136)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7182, 'f1': 0.7170546294311572, 'rmse': np.float64(3.12717124571073)}\n",
      "\n",
      "SELF-LEARNING ITERATION 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 21200/21200 [00:00<00:00, 29554.20 examples/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\3903225634.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1989' max='1989' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1989/1989 5:38:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.212300</td>\n",
       "      <td>1.855223</td>\n",
       "      <td>0.434189</td>\n",
       "      <td>0.452225</td>\n",
       "      <td>3.824029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.978800</td>\n",
       "      <td>1.842061</td>\n",
       "      <td>0.450241</td>\n",
       "      <td>0.469214</td>\n",
       "      <td>3.790670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.558900</td>\n",
       "      <td>1.873778</td>\n",
       "      <td>0.455859</td>\n",
       "      <td>0.477448</td>\n",
       "      <td>3.872647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on Filipino Validation Set: {'accuracy': 0.45585874799357945, 'f1': 0.4774484475510348, 'rmse': np.float64(3.8726465954551714)}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on English validation Set: {'accuracy': 0.7226, 'f1': 0.7211250310867204, 'rmse': np.float64(3.0958036113422955)}\n",
      "\n",
      "Best overall model was from iteration 1, epoch 3.0 with F1 = 0.4917\n"
     ]
    }
   ],
   "source": [
    "self_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8d845",
   "metadata": {},
   "source": [
    "## **Investigating the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bba031",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './results/sl_adv/xlm-roberta-base/iter_1/checkpoint-1875'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e0bb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4984/4984 [00:00<00:00, 25649.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "fil_val_dataset = Dataset.from_pandas(fil_test_df).map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23008\\4207010283.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
    "\n",
    "predictions = trainer.predict(fil_val_dataset)\n",
    "logits = predictions.predictions\n",
    "true_labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fcaf62ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4583    0.6790    0.5473       162\n",
      "           1     0.4957    0.3239    0.3918       352\n",
      "           2     0.3947    0.4615    0.4255        65\n",
      "           3     0.1724    0.1111    0.1351        45\n",
      "           4     0.2632    0.1370    0.1802        73\n",
      "           5     0.3578    0.4500    0.3986       260\n",
      "           6     0.7113    0.7120    0.7116      1104\n",
      "           7     0.3217    0.3007    0.3108       153\n",
      "           8     0.7734    0.4839    0.5953      1023\n",
      "           9     0.1672    0.4685    0.2464       222\n",
      "          10     0.1787    0.2979    0.2234       141\n",
      "          11     0.3304    0.4634    0.3858        82\n",
      "          12     0.3045    0.6512    0.4150       281\n",
      "          13     0.4500    0.8182    0.5806        99\n",
      "          14     0.6055    0.2646    0.3683       922\n",
      "\n",
      "    accuracy                         0.4825      4984\n",
      "   macro avg     0.3990    0.4415    0.3944      4984\n",
      "weighted avg     0.5614    0.4825    0.4917      4984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd14eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>match</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isang umano’y tinaguriang ‘shabu queen’ at lid...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.981036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthrax infection kumalat sa Cagayan</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.967823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TESDA: Mga tech-voc graduate swak sa trabaho</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.481570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nagkamit ng unang pwesto ang isang Filipina st...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>0.759778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEDA inaprub tapyas taripa sa e-vehicle</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.617909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Typhoon Betty, patuloy na humihina sa karagata...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.657265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>'Sarap maging tatay!' Post ng netizen tungkol ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.927840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>TESDA, maglulunsad ng training programs para s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.667123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>Anne Curtis, nagdiwang ng kaarawan sa ‘It’s Sh...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.615033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>Kamakailan lamang ay ibinida ng social media p...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.928071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4984 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     Isang umano’y tinaguriang ‘shabu queen’ at lid...      6   \n",
       "1                  Anthrax infection kumalat sa Cagayan      8   \n",
       "2          TESDA: Mga tech-voc graduate swak sa trabaho      9   \n",
       "3     Nagkamit ng unang pwesto ang isang Filipina st...     14   \n",
       "4               NEDA inaprub tapyas taripa sa e-vehicle      5   \n",
       "...                                                 ...    ...   \n",
       "4979  Typhoon Betty, patuloy na humihina sa karagata...      8   \n",
       "4980  'Sarap maging tatay!' Post ng netizen tungkol ...     10   \n",
       "4981  TESDA, maglulunsad ng training programs para s...      1   \n",
       "4982  Anne Curtis, nagdiwang ng kaarawan sa ‘It’s Sh...     14   \n",
       "4983  Kamakailan lamang ay ibinida ng social media p...     14   \n",
       "\n",
       "      predicted_label  match  confidence  \n",
       "0                   6   True    0.981036  \n",
       "1                   8   True    0.967823  \n",
       "2                   1  False    0.481570  \n",
       "3                  13  False    0.759778  \n",
       "4                   6  False    0.617909  \n",
       "...               ...    ...         ...  \n",
       "4979                9  False    0.657265  \n",
       "4980               11  False    0.927840  \n",
       "4981                1   True    0.667123  \n",
       "4982               10  False    0.615033  \n",
       "4983                0  False    0.928071  \n",
       "\n",
       "[4984 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = F.softmax(torch.tensor(logits), dim=-1)\n",
    "confidence_scores = torch.max(probs, dim=1).values.numpy()\n",
    "\n",
    "eval_df = fil_val_dataset.to_pandas()\n",
    "\n",
    "eval_df['predicted_label'] = predicted_labels\n",
    "eval_df['match'] = eval_df['label'] == eval_df['predicted_label']\n",
    "eval_df['confidence'] = confidence_scores\n",
    "eval_df = eval_df.drop(columns=['code_frames', 'input_ids', 'attention_mask'])\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('datasets/results/xlm-r_adv1_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
